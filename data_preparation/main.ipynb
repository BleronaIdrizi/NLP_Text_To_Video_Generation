{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Dataset (over 2M) Food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a comprehensive collection of recipes from all around the world, ranging from simple dishes like bread to elaborate meals like Swedish midsummer smorgasbords. It is designed to facilitate projects that involve food analysis, recipe generation, or multimedia applications related to culinary arts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General-purpose libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Text-to-Video and NLP Libraries\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# Video and Image Handling\n",
    "from moviepy import ImageSequenceClip, AudioFileClip\n",
    "import cv2  # OpenCV for image manipulation\n",
    "\n",
    "# Text-to-Speech\n",
    "from gtts import gTTS\n",
    "\n",
    "# Miscellaneous\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print dataset.\n",
    "def print_dataset(text, df):\n",
    "    print(\"\\n\" + text + \":\")\n",
    "    display(df.head())\n",
    "\n",
    "# Check for noisy data (e.g., special characters or unnecessary brackets)\n",
    "def find_noisy_data(column):\n",
    "    noisy_rows = df[column][df[column].str.contains(r\"[\\\\[\\\\]\\\\\\\\]|\\\\\\\"\")]\n",
    "    return noisy_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(\"../files/recipes_data.csv\")\n",
    "# df = pd.read_csv(\"../files/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>NER</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n",
       "      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"bite size shredded rice biscuits\", \"vanilla\"...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n",
       "      <td>[\"Place chipped beef on bottom of baking dish....</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"cream of mushroom soup\", \"beef\", \"sour cream...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n",
       "      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n",
       "      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"chicken gravy\", \"cream of mushroom soup\", \"c...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n",
       "      <td>[\"Combine first four ingredients and press in ...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[\"graham cracker crumbs\", \"powdered sugar\", \"p...</td>\n",
       "      <td>www.cookbooks.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n",
       "1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n",
       "2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n",
       "3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n",
       "4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n",
       "1  [\"Place chipped beef on bottom of baking dish....   \n",
       "2  [\"In a slow cooker, combine all ingredients. C...   \n",
       "3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n",
       "4  [\"Combine first four ingredients and press in ...   \n",
       "\n",
       "                                              link    source  \\\n",
       "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
       "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
       "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
       "3  www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
       "4  www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
       "\n",
       "                                                 NER               site  \n",
       "0  [\"bite size shredded rice biscuits\", \"vanilla\"...  www.cookbooks.com  \n",
       "1  [\"cream of mushroom soup\", \"beef\", \"sour cream...  www.cookbooks.com  \n",
       "2  [\"frozen corn\", \"pepper\", \"cream cheese\", \"gar...  www.cookbooks.com  \n",
       "3  [\"chicken gravy\", \"cream of mushroom soup\", \"c...  www.cookbooks.com  \n",
       "4  [\"graham cracker crumbs\", \"powdered sugar\", \"p...  www.cookbooks.com  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_dataset(\"Dataset\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2231142 entries, 0 to 2231141\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   title        object\n",
      " 1   ingredients  object\n",
      " 2   directions   object\n",
      " 3   link         object\n",
      " 4   source       object\n",
      " 5   NER          object\n",
      " 6   site         object\n",
      "dtypes: object(7)\n",
      "memory usage: 119.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# To gain knowledge about data types, run this command:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          1\n",
       "ingredients    0\n",
       "directions     0\n",
       "link           0\n",
       "source         0\n",
       "NER            0\n",
       "site           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Command for checking for null values:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fshirja e rreshtave me vlera null në kolonat me vlera null\n",
    "df = df.dropna(subset=df_columns)\n",
    "#new_df.to_csv(\"../files/Preprocessed_Kosovo_News_Articles_Dataset.csv\", index=False)\n",
    "\n",
    "# Shfaqja e dataseti-it të modifikuar\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Duplicate values in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command to search duplicates\n",
    "print(\"Duplicates: \" + str(df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duplicate values in title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df['title'].duplicated(keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rows filter based on the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the title is \"Cherry Nut Bars\"\n",
    "cherry_nut_bars = df[df['title'] == \"Cherry Nut Bars\"]\n",
    "\n",
    "# Display the filtered rows\n",
    "# print_dataset(\"cherry_nut_bars\", cherry_nut_bars)\n",
    "print(cherry_nut_bars.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find duplicates in NER column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df['NER'].duplicated(keep=False)]\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing nearly duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows before removing duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "# Identify duplicates based on 'title', 'NER', and 'ingredients'\n",
    "duplicates = df[df.duplicated(subset=['title', 'NER', 'ingredients'], keep=False)]\n",
    "\n",
    "# Log duplicate rows for verification\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates, keeping only the first occurrence\n",
    "df_cleaned = df.drop_duplicates(subset=['title', 'NER'], keep='first')\n",
    "\n",
    "# Number of rows after removing duplicates\n",
    "rows_after = len(df_cleaned)\n",
    "\n",
    "# Calculate the number of deleted rows\n",
    "deleted_rows = rows_before - rows_after\n",
    "\n",
    "df = df_cleaned\n",
    "\n",
    "# Logs\n",
    "print(f\"\\nRows before removing duplicates: {rows_before}\")\n",
    "print(f\"Rows after removing duplicates: {rows_after}\")\n",
    "print(f\"Number of rows deleted: {deleted_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rows after removing nearly duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the title is \"Cherry Nut Bars\"\n",
    "cherry_nut_bars = df[df['title'] == \"Cherry Nut Bars\"]\n",
    "\n",
    "# Display the filtered rows\n",
    "# print_dataset(\"cherry_nut_bars\", cherry_nut_bars)\n",
    "print(cherry_nut_bars.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each column in the DataFrame\n",
    "for column in df_columns:\n",
    "    nan_count = df[column].isna().sum()  # Count missing (NaN) values in the column\n",
    "    print(f\"The number of missing values detected in the column '{column}' is: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns 'City' and 'Salary'\n",
    "columns_to_delete = ['link', 'source', 'site']\n",
    "df.drop(columns=columns_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify titles with special characters\n",
    "print(\"Titles with special characters:\")\n",
    "print(df[df['title'].str.contains(r'[^\\w\\s]', regex=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters from titles\n",
    "df['title'] = df['title'].str.replace(r'[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display noisy data in the 'ingredients' column\n",
    "noisy_data = find_noisy_data('ingredients')\n",
    "print(\"Noisy Data in 'ingredients':\")\n",
    "print(noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display noisy data in the 'directions' column\n",
    "noisy_data = find_noisy_data('directions')\n",
    "print(\"Noisy Data in 'directions':\")\n",
    "print(noisy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean noisy data in the 'ingredients' column\n",
    "df['ingredients'] = df['ingredients'] \\\n",
    "    .str.replace(r'\\\\\"', '\"', regex=True) \\\n",
    "    .str.replace(r'[\\[\\]]', '', regex=True) \\\n",
    "    .str.replace(r'\\\\', '', regex=True) \\\n",
    "    .str.strip()\n",
    "\n",
    "# Verify the cleaned column\n",
    "print(\"Cleaned Ingredients Column:\")\n",
    "print(df['ingredients'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean noisy data in the 'ingredients' column\n",
    "df['directions'] = df['directions'] \\\n",
    "    .str.replace(r'\\\\\"', '\"', regex=True) \\\n",
    "    .str.replace(r'[\\[\\]]', '', regex=True) \\\n",
    "    .str.replace(r'\\\\', '', regex=True) \\\n",
    "    .str.strip()\n",
    "\n",
    "# Verify the cleaned column\n",
    "print(\"Cleaned Ingredients Column:\")\n",
    "print(df['directions'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
